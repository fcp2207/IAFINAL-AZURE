import chainlit as cl
import httpx 

API_URL = "https://ia-backend.ashybeach-87c13459.eastus.azurecontainerapps.io/predict"


@cl.on_message
async def on_message(message: cl.Message):
    # ğŸ”¹ Log para saber que se recibiÃ³ un mensaje desde Chainlit
    print(f"ğŸ“¥ Mensaje recibido desde Chainlit: {message.content}")

    # ğŸ”¹ Enviar mensaje de carga
    waiting_msg = cl.Message(content="â³ Generando respuesta, por favor espera...")
    await waiting_msg.send()

    try:
        # ğŸ”¹ Log para saber que se estÃ¡ enviando request al backend
        print(f"ğŸš€ Enviando solicitud POST a {API_URL}")

        async with httpx.AsyncClient(timeout=300.0) as client:
            response = await client.post(API_URL, json={"input_text": message.content})

        # ğŸ”¹ Log de respuesta
        print(f"ğŸ“¬ CÃ³digo de respuesta: {response.status_code}")

        if response.status_code == 200:
            data = response.json()
            answer = data.get("message", "âš ï¸ Error en la respuesta del backend.")
        else:
            answer = "âŒ Error al conectar con el modelo."

        print(f"âœ… Respuesta obtenida: {answer}")

        await waiting_msg.remove()
        await cl.Message(content=answer).send()

    except Exception as e:
        print(f"âš ï¸ Error en la solicitud: {e}")
        await waiting_msg.remove()
        await cl.Message(content="âŒ OcurriÃ³ un error al procesar tu solicitud.").send()
